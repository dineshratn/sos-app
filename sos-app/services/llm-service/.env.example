# LLM Service Environment Configuration

# Server
PORT=3007
HOST=0.0.0.0
ENV=development
LOG_LEVEL=info

# OpenAI (Primary LLM)
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_MODEL=gpt-4-turbo-preview
OPENAI_MAX_TOKENS=1000
OPENAI_TEMPERATURE=0.3

# Anthropic (Fallback LLM)
ANTHROPIC_API_KEY=your-anthropic-api-key-here
ANTHROPIC_MODEL=claude-3-sonnet-20240229
ANTHROPIC_MAX_TOKENS=1000

# Redis Cache
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_PASSWORD=redis123
REDIS_DB=2
CACHE_TTL=3600

# Security
JWT_SECRET=dev-secret-key-change-in-production
CORS_ORIGINS=http://localhost:3000,http://localhost:8080

# Feature Flags
ENABLE_CACHING=true
ENABLE_PII_ANONYMIZATION=true
ENABLE_FALLBACK_RESPONSES=true

# Rate Limiting
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_WINDOW=60
